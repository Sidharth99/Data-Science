{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/demand-forecasting/train_0irEZ2H.csv')\ntest_df = pd.read_csv('/kaggle/input/demand-forecasting/test_nfaJ3J5.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(4000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_df[['day', 'month', 'year']] = train_df['week'].str.split('/', expand=True)\n# test_df[['day', 'month', 'year']] = test_df['week'].str.split('/', expand=True)\ntrain_df.week = pd.to_datetime(train_df.week)\ntest_df.week = pd.to_datetime(test_df.week)\ntrain_df['day'] = train_df.week.dt.day\ntrain_df['month'] = train_df.week.dt.month\ntrain_df['year'] = train_df.week.dt.year\n\ntest_df['day'] = test_df.week.dt.day\ntest_df['month'] = test_df.week.dt.month\ntest_df['year'] = test_df.week.dt.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. one value is missing in total price column looking at count \n2. units sold has minimum value 1 and maximum 2876 which seems like an outlier because mean is 51.67 which is closer to minimum value. Also 75 percentile value is also 62"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df.units_sold==2876]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.dropna(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.hist(figsize=(10,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h = plt.hist(np.log(train_df.units_sold), bins=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(data=train_df, x='sku_id',  y='units_sold')\nticks = plt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(data=train_df[train_df.year==2011], x='sku_id',  y='units_sold')\nticks = plt.xticks(rotation=90)\nplt.show()\nsns.barplot(data=train_df[train_df.year==2012], x='sku_id',  y='units_sold')\nticks = plt.xticks(rotation=90)\nplt.show()\nsns.barplot(data=train_df[train_df.year==2013], x='sku_id',  y='units_sold')\nticks = plt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.pivot_table(index='sku_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sku_id_sortedby_unitssold = train_df.groupby('sku_id').describe()['units_sold']['mean'].sort_values(ascending=False).index\nsku_id_sortedby_unitssold = list(sku_id_sortedby_unitssold)\ntrain_df['sku_id_sortedby_unitssold'] = train_df['sku_id']\ntrain_df['sku_id_sortedby_unitssold'] = train_df['sku_id_sortedby_unitssold'].apply(lambda x: len(sku_id_sortedby_unitssold)-sku_id_sortedby_unitssold.index(x))\n\ntest_df['sku_id_sortedby_unitssold'] = test_df['sku_id']\ntest_df['sku_id_sortedby_unitssold'] = test_df['sku_id_sortedby_unitssold'].apply(lambda x: len(sku_id_sortedby_unitssold)-sku_id_sortedby_unitssold.index(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_by_sku_id = train_df.pivot_table(index='sku_id')['units_sold'].sort_values(ascending=False)\ntrain_df['avg_by_sku_id'] = train_df['sku_id'].copy()\ntrain_df['avg_by_sku_id'] = train_df.avg_by_sku_id.apply(lambda x:avg_by_sku_id[avg_by_sku_id.index==x].values[0])\n\ntest_df['avg_by_sku_id'] = test_df['sku_id'].copy()\ntest_df['avg_by_sku_id'] = test_df.avg_by_sku_id.apply(lambda x:avg_by_sku_id[avg_by_sku_id.index==x].values[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(15, 6))\nsns.barplot(data=train_df, x='store_id',  y='units_sold')\nticks = plt.xticks(rotation=90)\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_id_sortedby_unitssold = train_df.groupby('store_id').describe()['units_sold']['mean'].sort_values(ascending=False).index\nstore_id_sortedby_unitssold = list(store_id_sortedby_unitssold)\ntrain_df['store_id_sortedby_unitssold'] = train_df['store_id']\ntrain_df['store_id_sortedby_unitssold'] = train_df['store_id_sortedby_unitssold'].apply(lambda x: len(store_id_sortedby_unitssold)-store_id_sortedby_unitssold.index(x))\n\ntest_df['store_id_sortedby_unitssold'] = test_df['store_id']\ntest_df['store_id_sortedby_unitssold'] = test_df['store_id_sortedby_unitssold'].apply(lambda x: len(store_id_sortedby_unitssold)-store_id_sortedby_unitssold.index(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_by_store_id = train_df.pivot_table(index='store_id')['units_sold'].sort_values(ascending=False)\ntrain_df['avg_by_store_id'] = train_df['store_id'].copy()\ntrain_df['avg_by_store_id'] = train_df.avg_by_store_id.apply(lambda x:avg_by_store_id[avg_by_store_id.index==x].values[0])\n\ntest_df['avg_by_store_id'] = test_df['store_id'].copy()\ntest_df['avg_by_store_id'] = test_df.avg_by_store_id.apply(lambda x:avg_by_store_id[avg_by_store_id.index==x].values[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=train_df, x='total_price', y='units_sold')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us remove the outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.drop(train_df[train_df.units_sold>1500].index, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2)\nsns.scatterplot(data=train_df, x=np.log(train_df.total_price), y='units_sold', ax=ax[0])\nsns.scatterplot(data=train_df, x='base_price', y='units_sold', ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_df['log_transformed_tp'] = np.log(train_df.total_price)\n# test_df['log_transformed_tp'] = np.log(test_df.total_price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(15,5))\nsns.lineplot(data=train_df, x='week', y='units_sold')\nt = plt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig, ax = plt.subplots(1,2, figsize=(15,4))\n# sns.lineplot(data=train_df, x='day', y='units_sold', ax=ax[0])\n# sns.barplot(data=train_df, x='day', y='units_sold', ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(15,4))\nsns.lineplot(data=train_df, x='month', y='units_sold', ax=ax[0])\nsns.barplot(data=train_df, x='month', y='units_sold', ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(15,4))\nsns.lineplot(data=train_df, x='year', y='units_sold', ax=ax[0])\nsns.barplot(data=train_df, x='year', y='units_sold', ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.groupby(['year', 'month'])['units_sold'].mean().plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(data=train_df[train_df.year==2011], x='week', y='units_sold')\nplt.show()\nsns.lineplot(data=train_df[train_df.year==2012], x='week', y='units_sold')\nplt.show()\nsns.lineplot(data=train_df[train_df.year==2013], x='week', y='units_sold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=train_df[train_df.year==2011], x='month', y='units_sold')\nplt.show()\nsns.scatterplot(data=train_df[train_df.year==2012], x='month', y='units_sold')\nplt.show()\nsns.scatterplot(data=train_df[train_df.year==2013], x='month', y='units_sold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# group_by_day_df = train_df.groupby([\"month\", \"day\", \"sku_id\"]).describe()['units_sold']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_df['group_by_day'] = -1\n# for i in range(group_by_day_df['mean'].values.shape[0]):\n#     tup = group_by_day_df.index[i]\n#     m = group_by_day_df['mean'].values[i]\n#     train_df.loc[(train_df.month==tup[0])  & (train_df.day==tup[1]) & (train_df.sku_id==tup[2]), 'group_by_day'] = m\n    \n\n# test_df['group_by_day'] = -1\n# for i in range(group_by_day_df['mean'].values.shape[0]):\n#     tup = group_by_day_df.index[i]\n#     m = group_by_day_df['mean'].values[i]\n#     test_df.loc[(test_df.month==tup[0])  & (test_df.day==tup[1]) & (test_df.sku_id==tup[2]), 'group_by_day'] = m\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['diff_bp_tp'] = train_df['total_price'] - train_df['base_price']\ntrain_df['div_bp_tp'] = train_df['total_price']/train_df['base_price']\n\ntest_df['diff_bp_tp'] = test_df['total_price'] - test_df['base_price']\ntest_df['div_bp_tp'] = test_df['total_price']/test_df['base_price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['is_featured_sku', 'is_display_sku','diff_bp_tp' ,'div_bp_tp','sku_id_sortedby_unitssold', 'store_id_sortedby_unitssold', 'avg_by_sku_id', 'avg_by_store_id', 'day', 'month', 'year', 'units_sold']\ncorr = train_df[features].corr()\nfeatures = features[:-1]\ncorr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_X, val_X, train_y, val_y = train_test_split(train_df.loc[:, train_df.columns != 'units_sold'], train_df.units_sold, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RMSLE(actual, predicted):\n\n    predicted = np.array([np.log(np.abs(x+1.0)) for x in predicted])  # doing np.abs for handling neg values  \n    actual = np.array([np.log(np.abs(x+1.0)) for x in actual])\n    log_err = actual-predicted\n    \n    return 1000*np.sqrt(np.mean(log_err**2))\n\ndef get_e(model, df, target):\n    pred = model.predict(df)\n#     pred = np.exp(pred)\n    pred[pred<=0] = 52\n    er = RMSLE(target, pred)\n    print(er)\n    \ndef get_preds(model, df):\n    preds = model.predict(df)\n#     preds = np.exp(preds)\n    print(\"Pred<=0: \", len(preds[preds<=0]))\n    preds[preds<=0] = 52\n    return preds\n    \ndef preds_to_csv(m, preds):\n    pd.DataFrame({'record_ID':test_df.record_ID, 'units_sold':preds}).to_csv('datahack-demand-forecasting-'+m+'.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.preprocessing import MinMaxScaler\n\n# scaler = MinMaxScaler()\n# X = scaler.fit_transform(train_df[features])\n# X = X.reshape((X.shape[0], 9, 1))\n# test_set = scaler.transform(test_df[features])\n# test_set = test_set.reshape((test_set.shape[0], 9, 1))\n# y = train_df.units_sold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from keras.models import Sequential\n# from keras.layers import LSTM, Dense\n# from keras.metrics import MeanSquaredLogarithmicError\n\n# msle = MeanSquaredLogarithmicError()\n# model = Sequential()\n# model.add(LSTM(32, activation='relu', input_shape=(9,1)))\n# model.add(Dense(1))\n# model.compile(optimizer='RMSprop', loss='mean_squared_error', metrics=[msle])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.fit(X, y, epochs=50, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(\"Training:\")\n# lstm_train_preds = get_preds(model=model, df=X)\n# get_e(model=model, df=X, target=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lstm_preds = get_preds(model=model, df=test_set)\n# preds_to_csv('lstm', lstm_preds.reshape(lstm_preds.shape[0], ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from catboost import CatBoostRegressor\n\n# cbr = CatBoostRegressor()\n# cbr.fit(train_df[features], train_df.units_sold)\n\n# print(\"Training:\")\n# cbr_train_preds = get_preds(model=cbr, df=train_df[features])\n# get_e(model=cbr, df=train_df[features], target=train_df.units_sold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cbr_preds = get_preds(model=cbr, df=test_df[features])\n# preds_to_csv('cbr', cbr_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import RepeatedKFold, cross_val_score, KFold, StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training:\")\nlgb_train_preds = get_preds(model=lgb, df=train_df[features])\nget_e(model=lgb, df=train_df[features], target=train_df.units_sold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def runLGB(Xtrain, ytrain, Xval, yval, Xtest = None):\n    params = {\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': 'l1',\n    #'max_depth': 9, \n    'learning_rate': 0.1\n    ,'verbose': 1\n    , \"min_data_in_leaf\" : 10\n    }\n\n    n_estimators = 800\n    early_stopping_rounds = 10\n\n    d_train = lgb.Dataset(Xtrain.copy(), label=ytrain.copy())\n    d_valid = lgb.Dataset(Xval.copy(), label=yval.copy())\n    watchlist = [d_train, d_valid]\n\n    model = lgb.train(params, d_train, n_estimators\n                      , valid_sets = [d_train, d_valid]\n                      , verbose_eval=n_estimators\n                      , early_stopping_rounds=early_stopping_rounds)\n\n    preds = model.predict(Xval, num_iteration=model.best_iteration)\n    err = RMSLE(yval, preds)\n    \n    preds_test = model.predict(Xtest, num_iteration=model.best_iteration)\n    return  preds, err, preds_test, model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_val, err, pred_test,model = runLGB(train_X[features], train_y, val_X[features], val_y, test_df[features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_preds = get_preds(model=model, df=test_df[features])\npreds_to_csv('lgb', lgb_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a =model.feature_importance(importance_type='split')\nfeature = pd.DataFrame(model.feature_name(), columns = ['feature'])\nfeature['importance'] = a\nfeature = feature.sort_values(by = ['importance'], ascending = False)\nfeature.head(11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrfr=RandomForestRegressor(n_estimators=300)\n# rfr.fit(train_df[features], np.log(train_df.units_sold))\nrfr.fit(train_df[features], train_df.units_sold)\n\nprint(\"Training:\")\nrfr_train_preds = get_preds(model=rfr, df=train_df[features])\nget_e(model=rfr, df=train_df[features], target=train_df.units_sold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr_preds = get_preds(model=rfr, df=test_df[features])\npreds_to_csv('rfr', rfr_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrfr=RandomForestRegressor(n_estimators=300,max_depth=100,n_jobs=-1)\nrfr2.fit(train_X[features], train_y)\n\nprint(\"Training:\")\nrfr_train_preds = get_preds(model=rfr2, df=train_X[features])\nget_e(model=rfr, df=train_X[features], target=train_y)\nprint(\"Testing:\")\nrfr_test_preds = get_preds(model=rfr2, df=val_X[features])\nget_e(model=rfr, df=val_X[features], target=val_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,1, figsize=(10,8))\nsns.lineplot(data=val_X, x='week',y=val_y, ax=ax[0])\nsns.lineplot(data=val_X, x='week', y=rfr_test_preds, color='red', ax=ax[1])\nax[1].set_ylabel(\"units_sold\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,1, figsize=(10,8))\nsns.scatterplot(data=val_X, x='month',y=val_y, ax=ax[0])\nsns.scatterplot(data=val_X, x='month', y=rfr_test_preds, color='red', ax=ax[1])\nax[1].set_ylabel(\"units_sold\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrfr=RandomForestRegressor(n_estimators=200, max_depth=100,n_jobs=-1)\nrfr.fit(train_df[features], train_df.units_sold)\n\nprint(\"RFR:\")\nget_e(rfr)\nrfr_preds = get_preds(rfr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_to_csv('rfr', rfr_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import gc\n\n# del rfr\n# del cbr\n# del gbr\n# del lr\n\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\n# # Create the parameter grid based on the results of random search \n# param_grid = {\n#     'bootstrap': [True],\n#     'max_depth': [80, 90, 100, 110],\n#     'min_samples_leaf': [3, 4, 5],\n#     'min_samples_split': [8, 10, 12],\n#     'n_estimators': [100, 200, 300, 400]\n# }\n# # Create a based model\n# rf = RandomForestRegressor()\n# # Instantiate the grid search model\n# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n#                           cv = 3, n_jobs = -1, verbose = 2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# grid_search.fit(train_df[features], train_df.units_sold)\n\n# print(\"GS RFR:\")\n# get_e(grid_search)\n# gs_preds = get_preds(grid_search)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(\"GS RFR:\")\n# get_e(grid_search)\n# gs_preds = get_preds(grid_search)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrfr = RandomForestRegressor()\nrfr.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}