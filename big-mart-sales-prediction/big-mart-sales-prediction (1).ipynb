{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/train.csv')\ntest_df = pd.read_csv('/kaggle/input/test.csv')\nsubmit = pd.read_csv('/kaggle/input/Submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.hist(figsize=(8,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h = plt.hist((np.power(train_df.Item_Outlet_Sales, 1/3)), bins=70)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_df.Item_Outlet_Sales = np.power(train_df.Item_Outlet_Sales, 1/3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = []\ncat_cols = []\n\nfor col in train_df.columns:\n    if train_df[col].dtype=='int64' or train_df[col].dtype=='float64':\n        num_cols.append(col)\n    else:\n        cat_cols.append(col)\ncat_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cat_cols:\n    d = dict()\n    d[col] = train_df[col].unique()\n    if len(d[col]) < 20:\n        print(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.Item_Fat_Content.unique())\ntrain_df.replace({'reg':'Regular','LF':'Low Fat','low fat':'Low Fat'},inplace = True)\ntest_df.replace({'reg':'Regular','LF':'Low Fat','low fat':'Low Fat'},inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Item_Category'] = train_df['Item_Identifier'].apply(lambda x: x[0:2]).map({'FD':'Food',\n                                                              'NC':'Non-Consumable',\n                                                              'DR':'Drinks'})\ntest_df['Item_Category'] = test_df['Item_Identifier'].apply(lambda x: x[0:2]).map({'FD':'Food',\n                                                              'NC':'Non-Consumable',\n                                                              'DR':'Drinks'})\ncat_cols.append('Item_Category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cat_cols[1:]:\n    sns.barplot(data=train_df, x=col, y='Item_Outlet_Sales')\n    t = plt.xticks(rotation=90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(data=train_df, x='Outlet_Establishment_Year', y='Item_Outlet_Sales')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#x = 70, 138, 202\nsns.scatterplot(data=train_df, x='Item_MRP', y='Item_Outlet_Sales')\nplt.plot([70, 70], [0,12000])\nplt.plot([137, 137], [0,12000])\nplt.plot([203, 203], [0,12000])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 0-70 \n* 71-138\n* 139-202\n* 203-..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# def func(x):\n#     if x<71:\n#         return 1\n#     elif x<139:\n#         return 2\n#     elif x<203:\n#         return 3\n#     else:\n#         return 4\n# train_df['Item_MRP_Classes'] = train_df.Item_MRP.apply(lambda x:func(x))\n# test_df['Item_MRP_Classes'] = test_df.Item_MRP.apply(lambda x:func(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train_df.corr()\ncorr['Item_Outlet_Sales']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = train_df.groupby(['Item_Category', 'Item_Fat_Content', 'Item_Type']).describe()['Item_Weight']['mean'].reindex()\n_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(_.index)):\n    row = _.index[i]\n    train_df.loc[(train_df['Item_Weight'].isnull()) & (train_df['Item_Category']==row[0]) & (train_df['Item_Fat_Content']==row[1]) & (train_df['Item_Type']==row[2]), 'Item_Weight'] = _.values[i]\n    \ntrain_df['Item_Weight'] = train_df['Item_Weight'].fillna((train_df['Item_Weight']).mean())\n\nfor i in range(len(_.index)):\n    row = _.index[i]\n    test_df.loc[(test_df['Item_Weight'].isnull()) & (test_df['Item_Category']==row[0]) & (test_df['Item_Fat_Content']==row[1]) & (test_df['Item_Type']==row[2]), 'Item_Weight'] = _.values[i]\n\ntest_df['Item_Weight'] = test_df['Item_Weight'].fillna((test_df['Item_Weight']).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.groupby(['Outlet_Location_Type','Outlet_Identifier'])['Outlet_Type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.groupby(['Outlet_Location_Type','Outlet_Identifier', 'Outlet_Type'])['Outlet_Size'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So Outlets OUT017, OUT045, OUT010 have outlet_size as missing values.\nNow\n1. Since OUT010 is a Grocery Store of tier 3 we can fill with medium in outlet_size\n2. Since OUT017 and OUT045 are of supermarkettype 1 of tier 2, it's outlet_size should be small","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df['Outlet_Identifier']=='OUT010'] = \\\n    train_df[train_df['Outlet_Identifier']=='OUT010'].fillna('Medium', axis=0)\ntrain_df[train_df['Outlet_Identifier']=='OUT045'] = \\\n    train_df[train_df['Outlet_Identifier']=='OUT045'].fillna('Small', axis=0)\ntrain_df[train_df['Outlet_Identifier']=='OUT017'] = \\\n    train_df[train_df['Outlet_Identifier']=='OUT017'].fillna('Small', axis=0)\n\ntest_df[test_df['Outlet_Identifier']=='OUT010'] = \\\n    test_df[test_df['Outlet_Identifier']=='OUT010'].fillna('Medium', axis=0)\ntest_df[test_df['Outlet_Identifier']=='OUT045'] = \\\n    test_df[test_df['Outlet_Identifier']=='OUT045'].fillna('Small', axis=0)\ntest_df[test_df['Outlet_Identifier']=='OUT017'] = \\\n    test_df[test_df['Outlet_Identifier']=='OUT017'].fillna('Small', axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dum_cols = ['Item_Fat_Content', 'Outlet_Size',\n 'Outlet_Location_Type',\n 'Outlet_Type',\n 'Item_Category']\n\ncateg_cols = ['Item_Type','Outlet_Identifier']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nfor col in cat_cols:\n    le = LabelEncoder()\n    train_df[col] = le.fit_transform(train_df[col])\n    test_df[col] = le.transform(test_df[col])\n\n# train_df = pd.get_dummies(data=train_df, columns=dum_cols, drop_first=True)\n# test_df = pd.get_dummies(data=test_df, columns=dum_cols, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['fat_per_weight'] = train_df['Item_Fat_Content']/train_df['Item_Weight']\ntest_df['fat_per_weight'] = test_df['Item_Fat_Content']/test_df['Item_Weight']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# features = ['Item_Weight', 'Item_Visibility', 'Item_Type',\n#        'Item_MRP', 'Outlet_Identifier', 'Outlet_Establishment_Year',\n#        'Item_Fat_Content_Regular', 'Outlet_Size_Medium',\n#        'Outlet_Size_Small', 'Outlet_Location_Type_Tier 2',\n#        'Outlet_Location_Type_Tier 3', 'Outlet_Type_Supermarket Type1',\n#        'Outlet_Type_Supermarket Type2', 'Outlet_Type_Supermarket Type3',\n#        'Item_Category_Food', 'Item_Category_Non-Consumable', 'Item_Outlet_Sales']\n# corr = train_df[features].corr()\n# features = features[:-1]\n# corr['Item_Outlet_Sales']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['Item_Fat_Content', 'Item_Visibility', 'fat_per_weight', \n       'Item_Type', 'Item_MRP', 'Outlet_Identifier',\n        'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Establishment_Year',\n       'Outlet_Type', 'Item_Category', 'Item_Outlet_Sales']\ncorr = train_df[features].corr()\nfeatures = features[:-1]\ncorr['Item_Outlet_Sales']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_X, val_X, train_y, val_y = train_test_split(train_df[features], train_df['Item_Outlet_Sales'], test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error as mse\ndef get_e(model, df, target):\n    pred = model.predict(df)\n    print(len(pred[pred<=0]))\n    pred[pred<=0] = 2200\n    e = mse(target, pred)\n    print(np.sqrt(e))\n\ndef preds_to_csv(model, name):\n    pred = model.predict(test_df[features])\n    pred[pred<=0] = 2200\n    submit['Item_Outlet_Sales'] = pred\n    submit.to_csv('big_mart_sales_'+name+'.csv', index=False)\n#     pd.DataFrame({'Item_Identifier':test_df.Item_Identifier, 'Outlet_Identifier':test_df.Outlet_Identifier, 'Item_Outlet_Sales':pred}).to_csv(name+'_big_mart_sales.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\nfrom sklearn.linear_model import LinearRegression\nimport xgboost as xgb\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rm -r *.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rfr = RandomForestRegressor()\n# rfr.fit(train_df[features], train_df.Item_Outlet_Sales)\n# get_e(rfr, val_X, val_y)\n# preds_to_csv(rfr, 'rfr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import KFold\n\n# gbr = GradientBoostingRegressor()\n# X = train_df[features].values\n# y = train_df['Item_Outlet_Sales'].values\n# kf = KFold(n_splits=3, random_state=42)\n# for train_index, test_index in kf.split(X):\n#     X_train, X_val = X[train_index], X[test_index]\n#     y_train, y_val = y[train_index], y[test_index]\n#     gbr.fit(X_train, y_train)\n#     get_e(gbr, X_val, y_val)\n\n# get_e(gbr, val_X, val_y)\n# preds_to_csv(gbr, 'k_fold_gbr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbr = GradientBoostingRegressor()\ngbr.fit(train_df[features], train_df.Item_Outlet_Sales)\nget_e(gbr, val_X, val_y)\npreds_to_csv(gbr, 'gbr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbr.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\n    \"learning_rate\": [0.01, 0.05, 0.1, 0.15, 0.2],\n    \"min_samples_split\": np.linspace(0.1, 1, 6),\n    \"min_samples_leaf\": np.linspace(0.1, 0.5, 5),\n    \"max_depth\":[2,3,4,5,8],\n    \"max_features\":[\"auto\", \"log2\",\"sqrt\"],\n    \"criterion\": [\"friedman_mse\"],\n    \"n_estimators\":[50, 75, 100, 125, 150]\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\ngrid_search = GridSearchCV(gbr, parameters, cv=2, n_jobs=-1, verbose=1)\ngrid_search.fit(train_df[features], train_df.Item_Outlet_Sales)\nget_e(grid_search, val_X, val_y)\npreds_to_csv(grid_search, 'grid_search')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lgbr = lgb.LGBMRegressor()\n# lgbr.fit(train_df[features], train_df.Item_Outlet_Sales)\n# get_e(lgbr, val_X, val_y)\n# preds_to_csv(lgbr, 'lgbr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lr = LinearRegression()\n# lr.fit(train_X, train_y)\n# get_e(lr, val_X, val_y)\n# preds_to_csv(lr, 'lr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# xgbr = xgb.XGBRegressor()\n# xgbr.fit(train_X, train_y)\n# get_e(xgbr, val_X, val_y)\n# preds_to_csv(xgbr, 'xgbr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# etr = ExtraTreesRegressor()\n# etr.fit(train_X, train_y)\n# get_e(etr, val_X, val_y)\n# preds_to_csv(etr, 'etr')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GBR with whole train data gives a good score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tpot import TPOTRegressor\n\ntpr = TPOTRegressor(generations=100, population_size=10, n_jobs=-1, early_stop=20, verbosity=3, random_state=42)\ntpr.fit(train_df[features], train_df.Item_Outlet_Sales)\nget_e(tpr, val_X, val_y)\npreds_to_csv(tpr, 'tpr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpr.fitted_pipeline_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}